# # 0shot
# ## cot
# For model -  Meta-Llama-3-8B-Instruct
# science - acc_struct: 31.17  |  acc_regex: 48.05  |  avg_sent_length: 76  |  min_length: 7  |  max_length: 86
# metaphor - acc_struct: 26.61  |  acc_regex: 37.90  |  avg_sent_length: 84  |  min_length: 17  |  max_length: 136
# all - acc_struct: 27.39  |  acc_regex: 39.64  |  avg_sent_length: 83  |  min_length: 7  |  max_length: 136
#
#
# For model -  Phi-3-mini-128k-instruct
# science - acc_struct: 41.56  |  acc_regex: 46.75  |  avg_sent_length: 197  |  min_length: 105  |  max_length: 163
# metaphor - acc_struct: 23.12  |  acc_regex: 30.91  |  avg_sent_length: 193  |  min_length: 95  |  max_length: 226
# all - acc_struct: 26.28  |  acc_regex: 33.63  |  avg_sent_length: 194  |  min_length: 95  |  max_length: 226
#
#
# For model -  Starling-LM-7B-alpha
# science - acc_struct: 38.96  |  acc_regex: 37.66  |  avg_sent_length: 122  |  min_length: 157  |  max_length: 98
# metaphor - acc_struct: 28.49  |  acc_regex: 31.72  |  avg_sent_length: 71  |  min_length: 25  |  max_length: 86
# all - acc_struct: 30.29  |  acc_regex: 32.74  |  avg_sent_length: 79  |  min_length: 25  |  max_length: 98
#



# ## nocot STRICT
# For model -  Meta-Llama-3-8B-Instruct
# science - acc_struct: 29.87  |  acc_regex: 29.87  |  avg_sent_length: 1  |  min_length: 1  |  max_length: 1
# metaphor - acc_struct: 27.69  |  acc_regex: 25.27  |  avg_sent_length: 1  |  min_length: 1  |  max_length: 3
# all - acc_struct: 28.06  |  acc_regex: 26.06  |  avg_sent_length: 1  |  min_length: 1  |  max_length: 3
#
#
# For model -  Phi-3-mini-128k-instruct
# science - acc_struct: 27.27  |  acc_regex: 42.86  |  avg_sent_length: 44  |  min_length: 2  |  max_length: 29
# metaphor - acc_struct: 25.54  |  acc_regex: 34.41  |  avg_sent_length: 43  |  min_length: 2  |  max_length: 57
# all - acc_struct: 25.84  |  acc_regex: 35.86  |  avg_sent_length: 43  |  min_length: 2  |  max_length: 57
#
#
# For model -  Starling-LM-7B-alpha
# science - acc_struct: 27.27  |  acc_regex: 24.68  |  avg_sent_length: 2  |  min_length: 1  |  max_length: 1
# metaphor - acc_struct: 25.81  |  acc_regex: 25.27  |  avg_sent_length: 1  |  min_length: 1  |  max_length: 36
# all - acc_struct: 26.06  |  acc_regex: 25.17  |  avg_sent_length: 1  |  min_length: 1  |  max_length: 36



# #### nocot RAW
# For model -  Meta-Llama-3-8B-Instruct
# science - acc_struct: 27.27  |  acc_regex: 51.95  |  avg_sent_length: 74  |  min_length: 80  |  max_length: 55
# metaphor - acc_struct: 16.13  |  acc_regex: 36.02  |  avg_sent_length: 76  |  min_length: 10  |  max_length: 89
# all - acc_struct: 18.04  |  acc_regex: 38.75  |  avg_sent_length: 76  |  min_length: 10  |  max_length: 89
#
#
# For model -  Phi-3-mini-128k-instruct
# science - acc_struct: 27.27  |  acc_regex: 46.75  |  avg_sent_length: 72  |  min_length: 77  |  max_length: 68
# metaphor - acc_struct: 25.54  |  acc_regex: 37.63  |  avg_sent_length: 71  |  min_length: 66  |  max_length: 80
# all - acc_struct: 25.84  |  acc_regex: 39.20  |  avg_sent_length: 71  |  min_length: 66  |  max_length: 80
#
#
# For model -  Starling-LM-7B-alpha
# science - acc_struct: 29.87  |  acc_regex: 38.96  |  avg_sent_length: 74  |  min_length: 68  |  max_length: 72
# metaphor - acc_struct: 29.84  |  acc_regex: 37.90  |  avg_sent_length: 75  |  min_length: 1  |  max_length: 74
# all - acc_struct: 29.84  |  acc_regex: 38.08  |  avg_sent_length: 75  |  min_length: 1  |  max_length: 74




# 1shot
## cot
# For model -  Meta-Llama-3-8B-Instruct
# science - acc_struct: 29.87  |  acc_regex: 44.16  |  avg_sent_length: 57  |  min_length: 48  |  max_length: 50
# metaphor - acc_struct: 32.26  |  acc_regex: 37.63  |  avg_sent_length: 44  |  min_length: 33  |  max_length: 43
# all - acc_struct: 31.85  |  acc_regex: 38.75  |  avg_sent_length: 47  |  min_length: 33  |  max_length: 50
#
#
# For model -  Phi-3-mini-128k-instruct
# science - acc_struct: 23.38  |  acc_regex: 33.77  |  avg_sent_length: 194  |  min_length: 119  |  max_length: 204
# metaphor - acc_struct: 17.74  |  acc_regex: 30.38  |  avg_sent_length: 176  |  min_length: 127  |  max_length: 217
# all - acc_struct: 18.71  |  acc_regex: 30.96  |  avg_sent_length: 179  |  min_length: 119  |  max_length: 217
#
#
# For model -  Starling-LM-7B-alpha
# science - acc_struct: 28.57  |  acc_regex: 38.96  |  avg_sent_length: 126  |  min_length: 155  |  max_length: 125
# metaphor - acc_struct: 25.54  |  acc_regex: 30.65  |  avg_sent_length: 103  |  min_length: 134  |  max_length: 95
# all - acc_struct: 26.06  |  acc_regex: 32.07  |  avg_sent_length: 107  |  min_length: 134  |  max_length: 125
#
#
# ## nocot
# For model -  Meta-Llama-3-8B-Instruct
# science - acc_struct: 33.77  |  acc_regex: 44.16  |  avg_sent_length: 31  |  min_length: 10  |  max_length: 21
# metaphor - acc_struct: 30.91  |  acc_regex: 31.45  |  avg_sent_length: 25  |  min_length: 1  |  max_length: 20
# all - acc_struct: 31.40  |  acc_regex: 33.63  |  avg_sent_length: 26  |  min_length: 1  |  max_length: 21
#
#
# For model -  Phi-3-mini-128k-instruct
# science - acc_struct: 24.68  |  acc_regex: 46.75  |  avg_sent_length: 93  |  min_length: 61  |  max_length: 52
# metaphor - acc_struct: 31.18  |  acc_regex: 37.37  |  avg_sent_length: 98  |  min_length: 50  |  max_length: 66
# all - acc_struct: 30.07  |  acc_regex: 38.98  |  avg_sent_length: 97  |  min_length: 50  |  max_length: 66
#
#
# For model -  Starling-LM-7B-alpha
# science - acc_struct: 36.36  |  acc_regex: 48.05  |  avg_sent_length: 176  |  min_length: 146  |  max_length: 422
# metaphor - acc_struct: 37.37  |  acc_regex: 40.86  |  avg_sent_length: 170  |  min_length: 119  |  max_length: 119
# all - acc_struct: 37.19  |  acc_regex: 42.09  |  avg_sent_length: 171  |  min_length: 119  |  max_length: 422


import matplotlib.pyplot as plt
import numpy as np
import matplotlib

matplotlib.rcParams.update({'font.size': 20})

# Example data
models = ['Llama', 'Starling', 'Phi']
variations = ['With CoT', 'Without CoT']
subcategories = ['Science', 'Metaphor']

# Accuracy values for each combination
# Structure: models x subcategories x variations
accuracies = np.array([
    [[48.0, 28.5], [37.9, 34.1]],  # Llama science (Cot vs noCOT) and metaphor (CoT vs noCoT)
    [[37.6, 41.5], [31.7, 32.8]],  # Starling
    [[46.7, 40.2], [30.9, 29.5]]   # Phi
])

# Parameters
n_models = len(models)
n_variations = len(variations)
n_subcategories = len(subcategories)
bar_width = 0.35  # Width of each bar
spacing = 0.2  # Space between bars for each model

# Colors and hatches
colors = ['orange', 'blue']
hatches = ['', '//']

# Positions of the bars on the y-axis
indices = np.arange(n_models) * (n_subcategories * (bar_width * n_variations + spacing) + spacing)

# Plotting
fig, ax = plt.subplots(figsize=(16, 10))

for i in range(n_subcategories):
    for j in range(n_variations):
        # Offset the bars for each subcategory
        bar_positions = indices + i * (n_variations * bar_width + spacing) + j * bar_width
        bars = ax.barh(bar_positions, accuracies[:, i, j], bar_width, color=colors[j], hatch=hatches[i])

        # Add text annotations to the right of the middle point of each pair of bars
        if j == 0:  # Only add one annotation per subcategory
            middle_bar_positions = indices + i * (n_variations * bar_width + spacing) + bar_width * (n_variations / 2)
            for idx, pos in enumerate(middle_bar_positions):
                max_width = max(accuracies[idx, i, :])
                label_x_pos = 0.9
                ax.text(-5.5, pos - 0.2, f'{subcategories[i]}', va='center', fontstyle='italic')

        # Add value annotations to the right of each bar
        for bar in bars:
            width = bar.get_width()
            label_x_pos = width + 0.5
            ax.text(label_x_pos, bar.get_y() + bar.get_height() / 2, f'{width:.1f}', va='center')


# Draw horizontal lines to separate the bars for each model
for idx in range(1, n_models):
    y_pos = ((idx * (n_subcategories * (bar_width * n_variations + spacing) + spacing)) - spacing / 2) - 0.2
    ax.axhline(y=y_pos, color='gray', linestyle='--')

# Labels and title
ax.set_ylabel('Models & categories')
ax.set_xlabel('Accuracy %')
ax.set_title('Zero-Shot accuracy performance w/wo CoT per analogy category')
ax.set_yticks(indices + bar_width * n_variations / 2 + (n_subcategories - 1) * (bar_width + spacing) / 2)
ax.set_yticklabels(models, fontweight='bold', fontsize='large')

# Custom legend
handles = [
    plt.Line2D([0], [0], color=colors[1], lw=4, label=variations[1]),
    plt.Line2D([0], [0], color=colors[0], lw=4, label=variations[0])
]
ax.legend(handles=handles, loc='lower left')

# Display the plot
plt.tight_layout()
plt.show()


